{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Face Detection Webcam\n",
    "\n",
    "In this notebook, opencv face and body detection will be applied to webcam images.\n",
    "\n",
    "To run all cells in this notebook a webcam is required and the Delivery Tracker Django project must be running.\n",
    "\n",
    "To stop running the camera, interrupt the kernel.\n",
    "\n",
    "Code Adapted from:\n",
    "\n",
    "https://github.com/Xilinx/PYNQ/blob/master/boards/Pynq-Z2/base/notebooks/video/opencv_face_detect_webcam.ipynb\n",
    "\n",
    "References:\n",
    "\n",
    "https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "\n",
    "https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_upperbody.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Enter the serial number found on the back of your PYNQ-Z2 Board and the URL of your server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERIAL_NUMBER = \"911396a7-de99-49e0-b23d-643f48f08348\"\n",
    "URL = \"http://192.168.1.143:9595\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the overlay \n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "base = BaseOverlay(\"base.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initialize Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure output stream for new frames \n",
    "Mode = VideoMode(1280,720,24)\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(Mode,PIXEL_BGR)\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Initailize Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_LOG_LEVEL\"]=\"SILENT\"\n",
    "\n",
    "import cv2\n",
    "#initialize camera from openCV\n",
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "print(\"Capture device is open: \" + str(videoIn.isOpened()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Continuously Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "# if failed to load error, verify location and update file path\n",
    "face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_default.xml')\n",
    "body_cascade = cv2.CascadeClassifier('data/haarcascade_upperbody.xml')\n",
    "lastFrameUploaded = False\n",
    " \n",
    "if (face_cascade.empty() or body_cascade.empty()):\n",
    "    print(\"Failed to load cascade from file.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if lastFrameUploaded:\n",
    "            # last frame was sent to server, grab multiple frames to clear the frame buffer\n",
    "            for num in range(1, 6): videoIn.grab()\n",
    "            lastFrameUploaded = False\n",
    "        # read next image\n",
    "        ret, frame_vga = videoIn.read()\n",
    "        outframe = hdmi_out.newframe()\n",
    "        outframe[:] = frame_vga\n",
    "        gray_image = cv2.cvtColor(outframe, cv2.COLOR_BGR2GRAY)\n",
    "        # detect multiscale returns x, y, w, h\n",
    "        faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.4, minNeighbors=5, minSize=(75, 75))\n",
    "        upper_bodies = body_cascade.detectMultiScale(gray_image, 1.08, 1, minSize=(200, 200))\n",
    "\n",
    "        if (ret):    \n",
    "            if(len(faces)>0 or len(upper_bodies)>0):\n",
    "                lastFrameUploaded = True\n",
    "                frameList = outframe.tolist()\n",
    "                # Add your Django hosting server's IP\n",
    "                link = URL + \"/uploadFrame/\"\n",
    "                # Add your device ID\n",
    "                data = {'param': SERIAL_NUMBER, 'arr': frameList}\n",
    "                response = requests.post(link, json=data)\n",
    "                if(response.status_code==404):\n",
    "                    # server unable to locate device\n",
    "                    videoIn.release()\n",
    "                    hdmi_out.stop()\n",
    "                    del hdmi_out\n",
    "                    break\n",
    "        else:\n",
    "            # video input disconnected\n",
    "            videoIn.release()\n",
    "            hdmi_out.stop()\n",
    "            del hdmi_out\n",
    "            sys.exit()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    videoIn.release()\n",
    "    hdmi_out.stop()\n",
    "    del hdmi_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
